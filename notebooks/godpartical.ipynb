{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47614929-0596-44a6-b557-d7f85326bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a404673b-1e6e-4ae2-8127-7043d09873ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\avnis\\My_Projects\\Higgs-Boson-Classifier\\data\\Data science dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d6ede5-b9b1-4002-aadc-f0e01e299f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (250000, 33)\n",
      "   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
      "0   100000       138.470                       51.655        97.827    27.980   \n",
      "1   100001       160.937                       68.768       103.235    48.146   \n",
      "2   100002      -999.000                      162.172       125.953    35.635   \n",
      "3   100003       143.905                       81.417        80.943     0.414   \n",
      "4   100004       175.864                       16.915       134.805    16.405   \n",
      "\n",
      "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
      "0                  0.91           124.711                2.666   \n",
      "1               -999.00          -999.000             -999.000   \n",
      "2               -999.00          -999.000             -999.000   \n",
      "3                  9.00          -999.000             -999.000   \n",
      "4               -999.00          -999.000             -999.000   \n",
      "\n",
      "   DER_deltar_tau_lep  DER_pt_tot  ...  PRI_jet_num  PRI_jet_leading_pt  \\\n",
      "0               3.064      41.928  ...            2              67.435   \n",
      "1               3.473       2.078  ...            1              46.226   \n",
      "2               3.148       9.336  ...            1              44.251   \n",
      "3               3.310       0.414  ...            0            -999.000   \n",
      "4               3.891      16.405  ...            0            -999.000   \n",
      "\n",
      "   PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n",
      "0                2.150                0.444                 46.062   \n",
      "1                0.725                1.158               -999.000   \n",
      "2                2.053               -2.028               -999.000   \n",
      "3             -999.000             -999.000               -999.000   \n",
      "4             -999.000             -999.000               -999.000   \n",
      "\n",
      "   PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  \\\n",
      "0                    1.24                  -2.475         113.497  0.002653   \n",
      "1                 -999.00                -999.000          46.226  2.233584   \n",
      "2                 -999.00                -999.000          44.251  2.347389   \n",
      "3                 -999.00                -999.000           0.000  5.446378   \n",
      "4                 -999.00                -999.000           0.000  6.245333   \n",
      "\n",
      "   Label  \n",
      "0      s  \n",
      "1      b  \n",
      "2      b  \n",
      "3      b  \n",
      "4      b  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sample check\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bb69b4-3e7e-4f70-ac59-98ce2cc669be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting lable bin to 0/1\n",
    "if \"Label_bin\" not in df.columns:\n",
    "    df[\"Label_bin\"] = df[\"Label\"].apply(lambda x: 1 if x == \"s\" else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79486c92-e24c-49ef-880a-127738ceb3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"EventId\", \"Label\", \"Label_bin\", \"Weight\"], errors='ignore')\n",
    "y = df[\"Label_bin\"]\n",
    "sample_weights = df[\"Weight\"] if \"Weight\" in df.columns else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e1b10b-5c8e-4a1a-b715-a22898b4cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    # Adding missing flags\n",
    "    if X[col].isna().sum() > 0 or (-999.0 in X[col].values):\n",
    "        X[col + \"_missing_flag\"] = ((X[col] == -999.0) | X[col].isna()).astype(int)\n",
    "    \n",
    "    # Replacing -999 with NaN first\n",
    "    X[col] = X[col].replace(-999.0, np.nan)\n",
    "    \n",
    "    # Filling missing with median\n",
    "    median_val = X[col].median()\n",
    "    X[col] = X[col].fillna(median_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327647ef-fea2-447a-9286-cdeb85f6d0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train-Test Split\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, sample_weights, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c6289d-11be-4408-91c9-1c5da1788e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Scaling\n",
    "# ------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9313db2-20b2-404e-bea4-b6be6242431e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\avnis\\\\My_Projects\\\\Higgs-Boson-Classifier\\\\models\\\\scaler_higgs.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving scaler\n",
    "joblib.dump(scaler, rf\"C:\\Users\\avnis\\My_Projects\\Higgs-Boson-Classifier\\models\\scaler_higgs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0c866c-3ab9-409e-b1a1-7b5f18567759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=200, n_jobs=-1, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=50, max_depth=12, n_jobs=-1, random_state=42),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingClassifier(max_iter=100, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'  # will not give warning now\n",
    "        \n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab1918e-80e9-4f94-b380-6f58e6f3aa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression ...\n",
      "LogisticRegression -> Accuracy: 0.9983, F1: 0.0013, ROC-AUC: 0.8779, Precision: 0.2145, Recall: 0.0007\n",
      "Confusion Matrix:\n",
      "['123323', '1']\n",
      "['208', '0']\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00 123323.07339733066\n",
      "           1       0.21      0.00      0.00 207.6524791019955\n",
      "\n",
      "    accuracy                           1.00 123530.72587643265\n",
      "   macro avg       0.61      0.50      0.50 123530.72587643265\n",
      "weighted avg       1.00      1.00      1.00 123530.72587643265\n",
      "\n",
      "\n",
      "Training RandomForest ...\n",
      "RandomForest -> Accuracy: 0.9983, F1: 0.0162, ROC-AUC: 0.8901, Precision: 0.2166, Recall: 0.0084\n",
      "Confusion Matrix:\n",
      "['123317', '6']\n",
      "['206', '2']\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00 123323.07339733066\n",
      "           1       0.22      0.01      0.02 207.6524791019955\n",
      "\n",
      "    accuracy                           1.00 123530.72587643265\n",
      "   macro avg       0.61      0.50      0.51 123530.72587643265\n",
      "weighted avg       1.00      1.00      1.00 123530.72587643265\n",
      "\n",
      "\n",
      "Training HistGradientBoosting ...\n",
      "HistGradientBoosting -> Accuracy: 0.9973, F1: 0.0596, ROC-AUC: 0.9053, Precision: 0.0701, Recall: 0.0518\n",
      "Confusion Matrix:\n",
      "['123181', '142']\n",
      "['197', '11']\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00 123323.07339733066\n",
      "           1       0.07      0.05      0.06 207.6524791019955\n",
      "\n",
      "    accuracy                           1.00 123530.72587643265\n",
      "   macro avg       0.53      0.53      0.53 123530.72587643265\n",
      "weighted avg       1.00      1.00      1.00 123530.72587643265\n",
      "\n",
      "\n",
      "Training XGBoost ...\n",
      "XGBoost -> Accuracy: 0.9982, F1: 0.0321, ROC-AUC: 0.9313, Precision: 0.2185, Recall: 0.0173\n",
      "Confusion Matrix:\n",
      "['123310', '13']\n",
      "['204', '4']\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00 123323.07339733066\n",
      "           1       0.22      0.02      0.03 207.6524791019955\n",
      "\n",
      "    accuracy                           1.00 123530.72587643265\n",
      "   macro avg       0.61      0.51      0.52 123530.72587643265\n",
      "weighted avg       1.00      1.00      1.00 123530.72587643265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Train and Evaluate\n",
    "# ------------------------\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} ...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train, sample_weight=w_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred, sample_weight=w_test)\n",
    "    f1 = f1_score(y_test, y_pred, sample_weight=w_test)\n",
    "    roc = roc_auc_score(y_test, y_proba, sample_weight=w_test)\n",
    "    precision = precision_score(y_test, y_pred, sample_weight=w_test)\n",
    "    recall = recall_score(y_test, y_pred, sample_weight=w_test)\n",
    "    \n",
    "    # Confusion matrix & report\n",
    "    cm = confusion_matrix(y_test, y_pred, sample_weight=w_test)\n",
    "    report = classification_report(y_test, y_pred, sample_weight=w_test)\n",
    "    \n",
    "    # Storing results\n",
    "    results[name] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1\": f1,\n",
    "        \"ROC-AUC\": roc,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Confusion Matrix\": cm,\n",
    "        \"Classification Report\": report\n",
    "    }\n",
    "    trained_features = list(X_train.columns)\n",
    "    joblib.dump(trained_features, rf\"C:\\Users\\avnis\\My_Projects\\Higgs-Boson-Classifier\\models\\{name}_features.pkl\")\n",
    "    \n",
    "    # Printing metrics\n",
    "    print(f\"{name} -> Accuracy: {acc:.4f}, F1: {f1:.4f}, ROC-AUC: {roc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    for row in cm:\n",
    "        print([f\"{x:.0f}\" for x in row])  # rounding to integer\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    \n",
    "    # Saving model\n",
    "    joblib.dump(model, rf\"C:\\Users\\avnis\\My_Projects\\Higgs-Boson-Classifier\\models\\{name}_higgs_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
